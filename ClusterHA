#!/bin/bash

# Tips: DO THIS ON ALL NODES!

# sudo -i
# rm /root/cluster
# nano /root/cluster
# <-CTRL A-> <-CTRL C->
# <-CTRL O-> <-CTRL X->
# chmod +x /root/cluster
# reboot

# sudo crontab -e:
# "@reboot bash /root/cluster"
# reboot

# Remember to check if there are .contok and .vmok  files!
# sudo touch /srv/containers/.contok
# sudo touch /srv/virtualmachines/.vmok

function init {

 ##############################################################################
# ============================================================================ #

                                # =========== #
                               # Control Panel #
                                # =========== #

# Local Gateway
  export IP3="172.20.0.1"

# LAN 01
  export IP1="172.20.0.10"

# LAN 02
  export IP2="172.20.0.11"

                              # ================= #
                             # Advanced Parameters #
                              # ================= #

# Reserved NIC 01
  export HOSTNAME1="cluster-01"

# Reserved NIC 02
  export HOSTNAME2="cluster-02"

# If not setting this, will run as root...
  export USERNAME="administrador"

# All logs that are saved or discarded goes here
  export logpath="/var/log/gluster"

# Will run 7 times if 0 and 6!
  export beeplow="0"
  export beephigh="6"

  export loglow="0"
  export loghigh="6"

# Paths:
contpath="/srv/containers"
vmpath="/srv/virtualmachines"

# All texts and logs!
  export TEXT01="WARNING: Glusterd started manually"
  export TEXT02="Proceeding anyway."
  export TEXT03="ERROR: Glusterd not running!"
  export TEXT04="ERROR: Shutting down everything!"
  export TEXT05="ERROR: Reserved NIC not responding!"
  export TEXT06="ERROR: Gateway not found"
  export TEXT07="ERROR: The other node doesn't respond."
  export TEXT08="ERROR: Starting everything myself!"
  export TEXT09="ERROR: Containers volume was not found!"
  export TEXT10="Or maybe I just can't found the ctrl file. Check it out!"
  export TEXT11="ERROR: Shutting down everything to prevent Split Brain!"
  export TEXT12="ERROR: Virtual Machines volume was not found!"
  export TEXT13="Status: Everything is STOPPED on this node!"
  export TEXT14="Status: Everything is RUNNING on this node!"
  export TEXT15="Silence! Or I will aniquilate you!"
  export TEXT16="WARNING: Volume containers was mounted manually."
  export TEXT17="WARNING: Volume Virtual Machines was mounted manually."

# ============================================================================ #
 ##############################################################################



 ##############################################################################
# ============================================================================ #

                   # ========================= #
                  # High Availability Functions #
                   # ========================= #

# Resetting beep on first run!
  export beepsound="0"

# Check if everything if Ok with SSH to connect to another node
  eval $(ssh-agent) >/dev/null
  ssh-add /home/$USERNAME/.ssh/id_rsa >/dev/null

# This will keep this script running like a daemon!
  while true; do
    export data=$(date +"%H:%M %d.%m.%Y")
    sleep 5
    cluster00
  done
}

# 00 - Check if GlusterFS service is Running
function cluster00 {
  systemctl is-active --quiet glusterd && {
    cluster01
  } || {
    systemctl start glusterd.service
    systemctl is-active --quiet glusterd && {
    textlog "$TEXT01"
    textlog "$TEXT02"
      cluster01
    } || {
      textlog "$TEXT03"
      textlog "$TEXT04"
      beeps "2000" "2000"
      setpid "0" >/dev/null
      cluster07
    }
  }
}

# 01 - Ping the other node through reserved NIC
function cluster01 {
  if ping -c 1 "$HOSTNAME1" >/dev/null && ping -c 1 "$HOSTNAME2" >/dev/null; then
    cluster02
  else
    textlog "$TEXT05"
    textlog "$TEXT04"
    beeps "1000" "2000"
    setpid "0" >/dev/null
    cluster07
  fi
}

# 02 - Ping Gateway
function cluster02 {
  if ping -c 1 $IP3 >/dev/null; then
    cluster03
  else
    textlog "$TEXT06"
    textlog "$TEXT04"
    beeps "2000" "1000"
    setpid "0" >/dev/null
    cluster07
  fi
}

# 03 - Ping the other node
function cluster03 {
  if ping -c 1 $IP1 >/dev/null && ping -c 1 $IP2 > /dev/null; then
    cluster04
  else
    textlog "$TEXT07"
    textlog "$TEXT08"
    setpid "1" >/dev/null
    cluster07
  fi
}

# 04 - Checking for .lockha file on the other node
function cluster04 {
  [ "$HOSTNAME" = "$HOSTNAME1" ] && {
    checking=$(ssh $USERNAME@$HOSTNAME2 "cat /home/$USERNAME/.lockha") &&
    cluster05
  } || {
    checking=$(ssh $USERNAME@$HOSTNAME1 "cat /home/$USERNAME/.lockha") &&
    cluster05
  }
}

# 05 - Checking $contpath volume!
function cluster05 {
  [ -f "$contpath/.contok" ] && {
    cluster06
  } || {
    trymnt "$contpath"
    [ "$checkmnt" = "yes" ] && {
      textlog "$TEXT16"
      textlog "$TEXT02"
      cluster06
    } || {
      textlog "$TEXT09"
      textlog "$TEXT10"
      textlog "$TEXT11"
      beeps "1000" "1000"
      setpid "0" >/dev/null
      cluster07
    }
  }
}

# 06 - Checking $vmpath volume!
function cluster06 {
  [ -f "$vmpath/.vmok" ] && {
    cluster07
  } || {
    trymnt "$vmpath"
    [ "$checkmnt" = "yes" ] && {
      textlog "$TEXT17"
      textlog "$TEXT02"
      cluster07
    } || {
      textlog "$TEXT12"
      textlog "$TEXT10"
      textlog "$TEXT11"
      beeps "1000" "1000"
      setpid "0" >/dev/null
      cluster07
    }
  }
}

# 07 - Starting or stopping all containers and VMs accordingly
# If stopping, will wait 20s!
function cluster07 {
  export beepsound="0"

  [ "$checking" = "1" ] && {
    setpid "0" >/dev/null
    dockerctrl stop && >/dev/null
    vmctrl "--state-running" "shutdown" && >/dev/null
    textlog "$TEXT13"
  } || {
    setpid "1" >/dev/null
    sleep 20
    dockerctrl start && >/dev/null
    vmctrl "--state-shutoff" "start" && >/dev/null
    textlog "$TEXT14"
  }
}

                            # =============== #
                           # Control Functions #
                            # =============== #

# This starts or stops all containers!
function dockerctrl {
  docker "$1" $(docker ps -a -q)
}

# This starts or stops all virtual machines!
function vmctrl {
  for i in $(virsh list --all "$1" | awk '{print $2}' | grep -v Nome); do
    virsh "$2" "$i"
  done
}

# Setting PID control file on "/home/$USERNAME/.lockha".
# This randomly ensures that we don't fall on a ping-pong situation,
# with the machine nodes getting the same number for .lockha file!
function setpid {
  sleep $((RANDOM%5))
  echo "$1" > /home/"$USERNAME"/.lockha
}

# Just some logging
function textlog {
  echo "$data $1" | tee -a $logpath

  sizelog=$(du --apparent-size --block-size=1 $logpath | awk {print'$1'})
  [ "$sizelog" -ge "50000000" ] && {
    logmngr
  } || {
    echo "." > /dev/null
  }
}

# All beep configurations are here.
function beeps {
  [ "$beepsound" -ge "$beeplow" ] && [ "$beepsound" -le "$beephigh" ] && {
    modprobe pcspkr
    env -u SUDO_GID -u SUDO_COMMAND -u SUDO_USER -u SUDO_UID beep -f "$1" -l 200 -r 1
    env -u SUDO_GID -u SUDO_COMMAND -u SUDO_USER -u SUDO_UID beep -f "$2" -l 200 -r 1
    export beepsound=$(($beepsound+1))
  } || {
    textlog "$TEXT15"
  }
}

function trymnt {
  checkmnt="0"
  /bin/mount "$1"
  export checkmnt=$(/etc/mtab | grep "$1" 1>/dev/null && echo yes || echo no)
}

function logmgr {
  rm -rf /home/$USERNAME/.gluster_log
  rm -rf $logpath

  touch $logpath
  ln -s $logpath /home/$USERNAME/.gluster_log
}

# ============================================================================ #
 ##############################################################################

                                  #######
                                 # Start #
                                  #######

# Prepare the Logs
logmgr

# Let's get Started!
init

exit 1
